{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07812195])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"WeeklyFinalData.csv\"\n",
    "data = read(path)\n",
    "\n",
    "date = data[\"Date\"]\n",
    "data.drop(\"Date\", axis=1, inplace=True)\n",
    "x_data, y_data = buildTrain(data, futureWeek=4)\n",
    "\n",
    "\n",
    "a = sc.fit_transform(y_data[:,1].reshape(-1,1))\n",
    "2000/(sc.data_max_-sc.data_min_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "    \n",
    "    x_train_data = x_data[:int(x_data.shape[0]*0.8)]\n",
    "    x_test_data = x_data[int(x_data.shape[0]*0.8):]\n",
    "    y_train_data = y_data[:int(x_data.shape[0]*0.8)]\n",
    "    y_test_data = y_data[int(x_data.shape[0]*0.8):]\n",
    "#     ## Data split\n",
    "#     x_train = x_data[0:int(x_data.shape[0]*0.8)]\n",
    "#     x_test = x_data[int(x_data.shape[0]*0.8):]\n",
    "    \n",
    "#     y_train = y_data[0:int(y_data.shape[0]*0.8)]\n",
    "#     y_test = y_data[int(y_data.shape[0]*0.8):]\n",
    "    \n",
    "    ## Normalize\n",
    "#     x_train_scaled = sc.fit_transform(x_data)\n",
    "#     y_train_scaled = sc.fit_transform(y_data)\n",
    "    \n",
    "#     x_train_scaled = x_data\n",
    "#     y_train_scaled = y_data\n",
    "    \n",
    "#     return (x_train_scaled, y_train_scaled)\n",
    "\n",
    "    return (x_train_data, x_test_data, y_train_data, y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377, 18)\n",
      "(95, 18)\n",
      "(377, 4)\n",
      "(95, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train_data, x_test_data, y_train_data, y_test_data = get_data(4)\n",
    "\n",
    "print(x_train_data.shape)\n",
    "print(x_test_data.shape)\n",
    "print(y_train_data.shape)\n",
    "print(y_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "#         x_train_scaled, y_train_scaled = get_data(nb_neuro)\n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.07\n",
    "        self.threshold_for_lr = 1e-6\n",
    "        \n",
    "        # Input data\n",
    "        self.x = tf.convert_to_tensor(x_train_scaled, np.float32)\n",
    "        self.y = tf.convert_to_tensor(y_train_scaled, np.float32)\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-2\n",
    "        \n",
    "        # Optimizer\n",
    "#         self.optimizer = tf.optimizers.SGD(self.learning_rate)\n",
    "        \n",
    "         # Hidden layer I\n",
    "        self.n_neurons_in_h1 = nb_neuro\n",
    "        self.W1 = tf.Variable(tf.random.truncated_normal([self.x.shape[1], self.n_neurons_in_h1], mean=0, stddev=1))\n",
    "        self.b1 = tf.Variable(tf.random.truncated_normal([self.n_neurons_in_h1], mean=0, stddev=1))\n",
    "\n",
    "        # Output layer\n",
    "        self.Wo = tf.Variable(tf.random.truncated_normal([self.n_neurons_in_h1, self.y.shape[1]], mean=0, stddev=1))\n",
    "        self.bo = tf.Variable(tf.random.truncated_normal([self.y.shape[1]], mean=0, stddev=1))\n",
    "\n",
    "        # Whether the network is acceptable\n",
    "        self.acceptable = False\n",
    "    \n",
    "    def forecast(self, x_test_scaled):\n",
    "    \n",
    "        x_test_scaled = tf.cast(x_test_scaled, tf.float32)\n",
    "        forecast_value = tf.nn.relu((tf.matmul(x_test_scaled, self.W1)+self.b1))\n",
    "        return forecast_value\n",
    "\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = tf.convert_to_tensor(x_train_scaled, np.float32)\n",
    "        self.y = tf.convert_to_tensor(y_train_scaled, np.float32)\n",
    "    \n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "#         self.x = tf.convert_to_tensor(x_train_scaled, np.float32)\n",
    "#         self.y = tf.convert_to_tensor(y_train_scaled, np.float32)\n",
    "        self.x = tf.concat([self.x, new_x_train.reshape(1,-1)],0)\n",
    "        self.y = tf.concat([self.y, new_y_train.reshape(1,-1)],0)\n",
    "    \n",
    "        # forward operation\n",
    "    def forward(self,  reg_strength= 0):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            y1 = tf.nn.relu((tf.matmul(self.x, self.W1)+self.b1))\n",
    "            yo = (tf.matmul(y1,self.Wo)+self.bo)\n",
    "\n",
    "            # performance measure\n",
    "            diff = yo-self.y\n",
    "            loss = tf.reduce_mean(diff**2) + (reg_strength/(self.Wo.shape[1]*(self.Wo.shape[0]+1)+self.W1.shape[1]*(self.W1.shape[0]+1))) * ((tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.Wo) + tf.nn.l2_loss(self.b1) + tf.nn.l2_loss(self.bo))*2)\n",
    "#             loss = tf.reduce_mean(diff**2, axis=0) + reg_strength * (tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.Wo) + tf.nn.l2_loss(self.b1) + tf.nn.l2_loss(self.bo))\n",
    "\n",
    "        return(yo, loss, tape)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adam(self,tape,loss):\n",
    "\n",
    "#         tape.watch([self.W1, self.Wo, self.b1, self.bo])\n",
    "        optimizer = tf.optimizers.Adam(self.learning_rate)\n",
    "        gradients = tape.gradient(loss, [self.W1, self.Wo, self.b1, self.bo])\n",
    "        optimizer.apply_gradients(zip(gradients, [self.W1, self.Wo, self.b1, self.bo]))\n",
    "    \n",
    "    def backward_RMS(self,tape,loss):\n",
    "\n",
    "        optimizer = tf.keras.optimizers.RMSprop(self.learning_rate)\n",
    "        gradients = tape.gradient(loss, [self.W1, self.Wo, self.b1, self.bo])\n",
    "        optimizer.apply_gradients(zip(gradients, [self.W1, self.Wo, self.b1, self.bo]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning the parameter\n",
    "def matching(network):\n",
    "\n",
    "    network.learning_rate = 1e-3\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        yo, loss, tape = network.forward()\n",
    "\n",
    "        if tf.reduce_all(tf.math.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            \n",
    "            network.acceptable = True\n",
    "            print(\"Matching finished - the network is acceptable\")\n",
    "            return(network)\n",
    "\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Save the current papameter\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "            \n",
    "            # tuning and check the loss performance of the next step\n",
    "            network.backward_Adam(tape,loss)\n",
    "            yo, loss, tape = network.forward()\n",
    "\n",
    "            # Confirm whether the adjusted loss value is smaller than the current one\n",
    "            if loss < loss_pre:\n",
    "\n",
    "                # Multiply the learning rate by 1.2\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "            # On the contrary, reduce the learning rate\n",
    "            else:\n",
    "\n",
    "                network = network_pre\n",
    "                \n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "                    network.acceptable = False\n",
    "                    # If true, return the current model parameters\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    return(network)\n",
    "\n",
    "                # On the contrary, maintain the original parameter and adjust the learning rate\n",
    "                else:\n",
    "                    network.learning_rate *= 0.7\n",
    "#                     print(\"B\",network.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    \n",
    "#     x_train_scaled, y_train_scaled = get_data(4)\n",
    "\n",
    "#     initial_x = x_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "#     initial_y = y_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "    min_y = tf.reduce_min(initial_y, axis=0)\n",
    "    res_y = initial_y-min_y\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "\n",
    "    network.W1 = tf.Variable(tf.cast(tf.transpose(reg.coef_), tf.float32))\n",
    "    network.b1 = tf.Variable(tf.convert_to_tensor(reg.intercept_, tf.float32))\n",
    "    network.Wo = tf.Variable(tf.convert_to_tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]], tf.float32))\n",
    "    network.bo = tf.Variable(tf.cast(min_y, tf.float32))\n",
    "\n",
    "    network.acceptable =True\n",
    "#     network.W1 = tf.cast(tf.transpose(reg.coef_), tf.float32)\n",
    "#     network.b1 = tf.convert_to_tensor(reg.intercept_, tf.float32)\n",
    "#     network.Wo = tf.convert_to_tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]], tf.float32)\n",
    "#     network.bo = tf.cast(min_y, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(1,-1))\n",
    "        loss.append((temp_network.forward()[1].numpy(),i))\n",
    "\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "#     sorted_index = [x[1] for x in sorted(loss, key = lambda x:sum(x[0]))]\n",
    "#     sorted_index = [x for x in sorted(loss, key = lambda x:x[0])]\n",
    "\n",
    "    \n",
    "    print(\"First:\",loss[sorted_index[0]])\n",
    "    print(\"Second:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    \n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "            \n",
    "#         W1_pre, b1_pre, Wo_pre, bo_pre = network.W1, network.b1, network.Wo, network.bo\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss, tape = network.forward(1e-2)\n",
    "\n",
    "        loss_pre = loss\n",
    "\n",
    "        network.backward_Adam(tape, loss)\n",
    "        yo, loss, tape = network.forward(1e-2)\n",
    "\n",
    "        if loss <= loss_pre:\n",
    "            if tf.reduce_all(tf.math.abs(yo-network.y) <= network.threshold_for_error):\n",
    "                network.learning_rate *= 1.2\n",
    "                print(\"Regularizing process\")\n",
    "\n",
    "            else:\n",
    "#                 network.W1, network.b1, network.Wo, network.bo = W1_pre, b1_pre, Wo_pre, bo_pre\n",
    "                network = network_pre\n",
    "\n",
    "                print(\"Regularizing finished(A)\")\n",
    "                return(network)\n",
    "#                     break\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            network = network_pre\n",
    "\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                network.learning_rate *= 0.7\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(\"Regularizing finished(B)\")\n",
    "                return(network)\n",
    "#                     break\n",
    "\n",
    "        if i == 99:\n",
    "            \n",
    "            return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    \n",
    "#     if network.acceptable:\n",
    "        \n",
    "    k = 1\n",
    "    p = network.W1.shape[1]\n",
    "\n",
    "    while True:\n",
    "\n",
    "\n",
    "\n",
    "        if k > p:\n",
    "\n",
    "            print(\"The number of neuro: \",p)\n",
    "            return(network)\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            network = regularizing(network)\n",
    "            network_pre = copy.deepcopy(network)\n",
    "\n",
    "            network.acceptable = False\n",
    "\n",
    "            network.W1 = tf.Variable(tf.concat([network.W1[:,:k-1],network.W1[:,k:]],1))\n",
    "            network.b1 = tf.Variable(tf.concat([network.b1[:k-1],network.b1[k:]],0))\n",
    "            network.Wo = tf.Variable(tf.concat([network.Wo[:k-1,:],network.Wo[k:,:]],0))\n",
    "\n",
    "#             print(network.W1.shape, network.Wo.shape, network.b1.shape)\n",
    "            network = matching(network)\n",
    "\n",
    "            if network.acceptable:\n",
    "\n",
    "                print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                p-=1\n",
    "\n",
    "\n",
    "            else:\n",
    "                network = network_pre\n",
    "                print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "                k+=1\n",
    "                    \n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    ## Test network\n",
    "# x_train_scaled, y_train_scaled = get_data(4)\n",
    "# initial_x = x_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "# initial_y = y_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "\n",
    "# network = Network(4, initial_x, initial_y)\n",
    "# initializing(network, initial_x, initial_y)\n",
    "\n",
    "# sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "# network.setData(x_train_scaled[sorted_index[:20]],y_train_scaled[sorted_index[:20]])\n",
    "\n",
    "\n",
    "    ## Set the random seed\n",
    "    tf.random.set_seed(5)\n",
    "\n",
    "    ## Find unsatisfied situation\n",
    "    yo, loss, tape = network.forward()\n",
    "    forward_info = [yo, loss, tape]\n",
    "    \n",
    "    undesired_index = tf.where(tf.math.abs(yo-network.y) > network.threshold_for_error)\n",
    "\n",
    "    \n",
    "#     print(tf.math.abs(yo-network.y))\n",
    "#     print(network.threshold_for_error)\n",
    "    print(undesired_index)\n",
    "#     print(undesired_index.shape[0])\n",
    "\n",
    "    ## Unsatisfied situation\n",
    "    for i in range(undesired_index.shape[0]):\n",
    "\n",
    "        k_data_num = undesired_index[i][0]\n",
    "        k_l = undesired_index[i][1]\n",
    "\n",
    "        undesired_data = tf.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the only data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = tf.concat([left_data, right_data], 0)\n",
    "\n",
    "    #     print(tf.subtract(remain_tensor, undesired_data).shape)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            gamma = tf.random.uniform(shape=[1,network.x.shape[1]])\n",
    "\n",
    "            subtract_undesired_data = tf.subtract(remain_tensor, undesired_data)\n",
    "            matmul_value = tf.matmul(gamma,tf.transpose(subtract_undesired_data))\n",
    "\n",
    "\n",
    "            if tf.reduce_all(matmul_value != 0):\n",
    "\n",
    "                while True:\n",
    "\n",
    "                    ## Find the tiny value: zeta\n",
    "                    zeta = tf.random.uniform(shape=[1])\n",
    "\n",
    "                    if tf.reduce_all(tf.multiply(tf.add(zeta,matmul_value),tf.subtract(zeta,matmul_value))<0):\n",
    "                        break\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = tf.transpose(tf.concat([w10,w11,w12],0))\n",
    "\n",
    "    #     ## The bias of input layer to hidden layer I\n",
    "        matual_value = tf.matmul(gamma,tf.transpose(undesired_data))\n",
    "\n",
    "        b10 = tf.subtract(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = tf.subtract(-1*zeta,matual_value)\n",
    "        b1_new = tf.reshape(tf.concat([b10,b11,b12],0),[3])\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        wo0 = tf.reshape(tf.one_hot(k_l,4,dtype=tf.float32) * wo0_value, shape=(1,-1))\n",
    "        wo1 = tf.reshape(tf.one_hot(k_l,4,dtype=tf.float32) * wo1_value, shape=(1,-1))\n",
    "        wo2 = tf.reshape(tf.one_hot(k_l,4,dtype=tf.float32) * wo2_value, shape=(1,-1))\n",
    "\n",
    "        Wo_new = tf.concat([wo0,wo1,wo2],0)\n",
    "\n",
    "\n",
    "    #     ## Add new neuroes to the network\n",
    "        network.W1 = tf.Variable(tf.concat([network.W1, W1_new],1), tf.float32)\n",
    "        network.b1 = tf.Variable(tf.concat([network.b1, b1_new],0), tf.float32)\n",
    "        network.Wo = tf.Variable(tf.concat([network.Wo, Wo_new],0), tf.float32)\n",
    "\n",
    "        yo, loss, tape = network.forward()\n",
    "    #     print(tf.math.abs(yo[k_data_num,k_l]-network.y[k_data_num,k_l]) <= network.threshold_for_error)\n",
    "        if tf.reduce_all(tf.math.abs(yo[k_data_num,k_l]-network.y[k_data_num,k_l]) <= network.threshold_for_error):\n",
    "            \n",
    "            if i==(undesired_index.shape[0]-1):\n",
    "                network.acceptable = True\n",
    "            \n",
    "            print(\"Cramming success!\")\n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "        \n",
    "# print(network.W1.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a instance of network\n",
    "- trained through the matching module, reorganizing module, and cramming module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_n: 20 number_data: 377\n",
      "11\n",
      "The data number: 20\n",
      "First: (0.04087187, 0)\n",
      "Second: (0.07909024, 2)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.00000376 0.00000101 0.00000083 0.        ]\n",
      " [0.00000203 0.00000203 0.00000036 0.00000018]\n",
      " [0.00000662 0.00000179 0.00000006 0.00000006]\n",
      " [0.00000101 0.00000089 0.00000006 0.00000024]\n",
      " [0.00000167 0.00000328 0.00000036 0.00000018]\n",
      " [0.00000322 0.00000274 0.00000089 0.00000077]\n",
      " [0.00000542 0.00000399 0.0000003  0.00000012]\n",
      " [0.00000131 0.0000034  0.         0.00000054]\n",
      " [0.00000119 0.00000644 0.0000003  0.00000042]\n",
      " [0.00000149 0.00000054 0.0000003  0.00000066]\n",
      " [0.00000703 0.00000638 0.0000003  0.00000048]\n",
      " [0.00000715 0.00000376 0.00000012 0.00000006]\n",
      " [0.00000644 0.00000536 0.00000006 0.00000024]\n",
      " [0.00000423 0.0000059  0.00000012 0.        ]\n",
      " [0.00000286 0.00000012 0.00000012 0.        ]\n",
      " [0.00000066 0.00000417 0.00000012 0.        ]\n",
      " [0.00000149 0.00000942 0.00000036 0.        ]\n",
      " [0.00000471 0.00000727 0.00000012 0.00000024]\n",
      " [0.00000232 0.00000727 0.00000012 0.00000042]\n",
      " [0.3753181  0.08476233 0.1098395  0.05810875]], shape=(20, 4), dtype=float32)\n",
      "Matching finished - the network is acceptable\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 4\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is acceptable\n",
      "Drop out the nero number: 2 / 4\n",
      "Regularizing process\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 3\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is acceptable\n",
      "Drop out the nero number: 3 / 3\n",
      "The number of neuro:  2\n",
      "True\n",
      "10\n",
      "The data number: 21\n",
      "First: (0.005836749, 2)\n",
      "Second: (0.0068482, 4)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.01986951 0.06945199 0.00541383 0.06999594]\n",
      " [0.05871511 0.00397789 0.02099007 0.04159617]\n",
      " [0.004067   0.02234453 0.00597948 0.01225376]\n",
      " [0.01995784 0.01963151 0.00542492 0.02590179]\n",
      " [0.01618862 0.0057506  0.0060513  0.05726844]\n",
      " [0.03818065 0.05319911 0.02343881 0.0609169 ]\n",
      " [0.05340415 0.00608885 0.03061056 0.01753896]\n",
      " [0.00320423 0.02202916 0.00245231 0.02899194]\n",
      " [0.02015615 0.01574165 0.00377452 0.01571155]\n",
      " [0.01305854 0.01949537 0.01101488 0.00405598]\n",
      " [0.02320278 0.00988626 0.01537085 0.01226848]\n",
      " [0.00219345 0.01390648 0.00108773 0.0034852 ]\n",
      " [0.00594234 0.00994688 0.00383151 0.02411383]\n",
      " [0.00248748 0.01619649 0.00241369 0.0020079 ]\n",
      " [0.01005888 0.01197624 0.00037289 0.00779653]\n",
      " [0.01191753 0.00127125 0.00007862 0.00293905]\n",
      " [0.00865227 0.01206332 0.00301963 0.01458722]\n",
      " [0.01752526 0.01526564 0.00288206 0.05612427]\n",
      " [0.03683561 0.02470821 0.02414542 0.00713044]\n",
      " [0.06169957 0.0363251  0.02614421 0.04571098]\n",
      " [0.12292713 0.04553246 0.0421831  0.06620634]], shape=(21, 4), dtype=float32)\n",
      "Matching finished - the network is acceptable\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 2\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 2\n",
      "The number of neuro:  2\n",
      "True\n",
      "9\n",
      "The data number: 22\n",
      "First: (0.0073913517, 3)\n",
      "Second: (0.008684631, 2)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.01891488 0.06943083 0.00374341 0.06346637]\n",
      " [0.0591411  0.00414187 0.02083534 0.03503406]\n",
      " [0.00053662 0.02310884 0.00169122 0.00201178]\n",
      " [0.03059536 0.02213973 0.01339716 0.01348954]\n",
      " [0.02584362 0.00358415 0.01352942 0.06917381]\n",
      " [0.04843414 0.05615073 0.02988821 0.06860632]\n",
      " [0.06802815 0.01087093 0.03834462 0.02401292]\n",
      " [0.01448911 0.01749891 0.0067783  0.03158879]\n",
      " [0.01006329 0.02034527 0.00090384 0.01591206]\n",
      " [0.00594378 0.01611853 0.00906396 0.00427514]\n",
      " [0.01907438 0.01223135 0.0147388  0.0107519 ]\n",
      " [0.00552613 0.01538944 0.00036722 0.00450093]\n",
      " [0.00639164 0.00970536 0.00317597 0.0229519 ]\n",
      " [0.00302768 0.01681149 0.00183845 0.0006426 ]\n",
      " [0.01049805 0.01157576 0.00037295 0.00571132]\n",
      " [0.010575   0.00038099 0.00096673 0.00493491]\n",
      " [0.00798494 0.01175755 0.00254637 0.01545465]\n",
      " [0.01755375 0.01559281 0.00284499 0.05569738]\n",
      " [0.03546631 0.0249052  0.02279931 0.0038932 ]\n",
      " [0.04081815 0.02747416 0.01834261 0.04259914]\n",
      " [0.06994873 0.01900262 0.04616344 0.06317395]\n",
      " [0.02487671 0.05961794 0.0739131  0.14116943]], shape=(22, 4), dtype=float32)\n",
      "Matching finished - the network is Unacceptable\n",
      "tf.Tensor(\n",
      "[[21  2]\n",
      " [21  3]], shape=(2, 2), dtype=int64)\n",
      "Cramming success!\n",
      "Cramming success!\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is acceptable\n",
      "Drop out the nero number: 1 / 8\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "The number of neuro:  7\n",
      "True\n",
      "8\n",
      "The data number: 23\n",
      "First: (0.0021773884, 3)\n",
      "Second: (0.0044059106, 0)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.00270122 0.05031335 0.004017   0.03844976]\n",
      " [0.04448819 0.01599878 0.02649993 0.02227044]\n",
      " [0.02429503 0.04071397 0.00990123 0.00501537]\n",
      " [0.05043101 0.03115338 0.00480318 0.0369904 ]\n",
      " [0.04402614 0.0030123  0.00055963 0.03940773]\n",
      " [0.04567969 0.04428834 0.04054236 0.05292243]\n",
      " [0.06202668 0.00450814 0.0301522  0.00115579]\n",
      " [0.01578808 0.05019665 0.01078683 0.02014494]\n",
      " [0.05551755 0.02411366 0.01563257 0.01429611]\n",
      " [0.04698819 0.05466449 0.02104568 0.00031328]\n",
      " [0.04341674 0.00833821 0.00571752 0.00607431]\n",
      " [0.01464945 0.02474916 0.00680107 0.01255655]\n",
      " [0.03588998 0.01932651 0.02388215 0.0053798 ]\n",
      " [0.00782007 0.02378225 0.00433666 0.00110096]\n",
      " [0.01105583 0.00845152 0.00185281 0.01413745]\n",
      " [0.03538662 0.02096719 0.02153969 0.02620167]\n",
      " [0.00590092 0.00852877 0.01037019 0.01278502]\n",
      " [0.00064981 0.00039035 0.00117934 0.03708601]\n",
      " [0.02863091 0.0195784  0.01249391 0.0119521 ]\n",
      " [0.03817427 0.01020211 0.06115746 0.0664373 ]\n",
      " [0.02512991 0.00173354 0.04563153 0.06992722]\n",
      " [0.04077661 0.05357724 0.00101405 0.00196761]\n",
      " [0.03973961 0.06394327 0.05263764 0.01645476]], shape=(23, 4), dtype=float32)\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "The number of neuro:  7\n",
      "True\n",
      "7\n",
      "The data number: 24\n",
      "First: (0.0044059106, 0)\n",
      "Second: (0.0049534235, 2)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.00270122 0.05031335 0.004017   0.03844976]\n",
      " [0.04448819 0.01599878 0.02649993 0.02227044]\n",
      " [0.02429503 0.04071397 0.00990123 0.00501537]\n",
      " [0.05043101 0.03115338 0.00480318 0.0369904 ]\n",
      " [0.04402614 0.0030123  0.00055963 0.03940773]\n",
      " [0.04567969 0.04428834 0.04054236 0.05292243]\n",
      " [0.06202668 0.00450814 0.0301522  0.00115579]\n",
      " [0.01578808 0.05019665 0.01078683 0.02014494]\n",
      " [0.05551755 0.02411366 0.01563257 0.01429611]\n",
      " [0.04698819 0.05466449 0.02104568 0.00031328]\n",
      " [0.04341674 0.00833821 0.00571752 0.00607431]\n",
      " [0.01464945 0.02474916 0.00680107 0.01255655]\n",
      " [0.03588998 0.01932651 0.02388215 0.0053798 ]\n",
      " [0.00782007 0.02378225 0.00433666 0.00110096]\n",
      " [0.01105583 0.00845152 0.00185281 0.01413745]\n",
      " [0.03538662 0.02096719 0.02153969 0.02620167]\n",
      " [0.00590092 0.00852877 0.01037019 0.01278502]\n",
      " [0.00064981 0.00039035 0.00117934 0.03708601]\n",
      " [0.02863091 0.0195784  0.01249391 0.0119521 ]\n",
      " [0.03817427 0.01020211 0.06115746 0.0664373 ]\n",
      " [0.02512991 0.00173354 0.04563153 0.06992722]\n",
      " [0.04077661 0.05357724 0.00101405 0.00196761]\n",
      " [0.03973961 0.06394327 0.05263764 0.01645476]\n",
      " [0.00327998 0.05367261 0.10359865 0.06324512]], shape=(24, 4), dtype=float32)\n",
      "Matching finished - the network is acceptable\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "The number of neuro:  7\n",
      "True\n",
      "6\n",
      "The data number: 25\n",
      "First: (0.0031718812, 1)\n",
      "Second: (0.0032822436, 0)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.00569832 0.04146755 0.00372684 0.03395516]\n",
      " [0.03714228 0.03049535 0.03473544 0.02630633]\n",
      " [0.03044629 0.05344677 0.01967204 0.01333821]\n",
      " [0.03945649 0.02463645 0.00884897 0.03597099]\n",
      " [0.03340143 0.00496298 0.00157481 0.03744864]\n",
      " [0.03707916 0.03700566 0.04485607 0.05417532]\n",
      " [0.05652869 0.00858867 0.02702975 0.00255471]\n",
      " [0.02175832 0.05400991 0.00590241 0.02089345]\n",
      " [0.06073874 0.02738678 0.01077628 0.01259065]\n",
      " [0.05169481 0.05730301 0.01667565 0.00251794]\n",
      " [0.04655278 0.00906801 0.01044321 0.00573438]\n",
      " [0.0153113  0.02670479 0.00870723 0.01269364]\n",
      " [0.03805697 0.02259332 0.02384496 0.00138515]\n",
      " [0.00785273 0.02391267 0.00593954 0.00280142]\n",
      " [0.01096386 0.0096367  0.0047285  0.01389205]\n",
      " [0.03797305 0.02482063 0.0173015  0.0294553 ]\n",
      " [0.00624132 0.01064831 0.00800717 0.0153653 ]\n",
      " [0.00063634 0.00123394 0.00041914 0.03771788]\n",
      " [0.03031087 0.02361357 0.01878285 0.0094161 ]\n",
      " [0.02291185 0.00901747 0.02548379 0.03966451]\n",
      " [0.03154808 0.00921196 0.05354643 0.06998485]\n",
      " [0.03176022 0.04072702 0.00407392 0.00909668]\n",
      " [0.02941269 0.04978901 0.02169508 0.00895631]\n",
      " [0.00990897 0.03690082 0.0668022  0.03840703]\n",
      " [0.08799791 0.04461098 0.0499891  0.02133018]], shape=(25, 4), dtype=float32)\n",
      "Matching finished - the network is acceptable\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "Regularizing finished(A)\n",
      "Matching finished - the network is Unacceptable\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "The number of neuro:  7\n",
      "True\n",
      "5\n",
      "The data number: 26\n",
      "First: (0.0017538284, 0)\n",
      "Second: (0.16708954, 1)\n",
      "Selecting module finish!\n",
      "tf.Tensor(\n",
      "[[0.00739974 0.03867489 0.00412983 0.02001482]\n",
      " [0.03411287 0.03446394 0.03196967 0.01729816]\n",
      " [0.03459185 0.05836231 0.02136809 0.01229239]\n",
      " [0.03189182 0.01674074 0.00110245 0.03692943]\n",
      " [0.02648205 0.01381779 0.00045013 0.03310394]\n",
      " [0.03561544 0.03331971 0.04332596 0.05273813]\n",
      " [0.06426853 0.00140834 0.01518261 0.00106138]\n",
      " [0.01590109 0.04846579 0.00652444 0.01582336]\n",
      " [0.05331248 0.02025789 0.00203443 0.0151813 ]\n",
      " [0.04654282 0.0530473  0.01232916 0.00453579]\n",
      " [0.04446334 0.0081352  0.01053947 0.00409222]\n",
      " [0.01861763 0.02808487 0.00065953 0.01087868]\n",
      " [0.03845978 0.02051407 0.01108116 0.0006336 ]\n",
      " [0.00722843 0.01995242 0.00013191 0.00776082]\n",
      " [0.01107091 0.0135873  0.00216675 0.00821501]\n",
      " [0.0376001  0.02857941 0.01747859 0.0311833 ]\n",
      " [0.00586265 0.01475698 0.01267844 0.01880324]\n",
      " [0.00238442 0.00462097 0.00726157 0.03484339]\n",
      " [0.0298813  0.02808702 0.01522529 0.01286477]\n",
      " [0.00713915 0.02533662 0.00323892 0.02099979]\n",
      " [0.02709877 0.01082778 0.05919462 0.06168526]\n",
      " [0.03586704 0.03954822 0.00844342 0.00818312]\n",
      " [0.0318563  0.04675543 0.01672673 0.00886953]\n",
      " [0.02583009 0.02061218 0.04220068 0.02489769]\n",
      " [0.06999886 0.02689821 0.01869613 0.00203013]\n",
      " [0.02209944 0.06510842 0.0438562  0.01909071]], shape=(26, 4), dtype=float32)\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n",
      "Regularizing process\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'acceptable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-73a9952dd619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myo\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_for_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macceptable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-22015f6b6ec8>\u001b[0m in \u001b[0;36mreorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mnetwork_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macceptable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'acceptable'"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "    \n",
    "# x_train_scaled, y_train_scaled = get_data(4)\n",
    "\n",
    "x_train_data, x_test_data, y_train_data, y_test_data = get_data(4)\n",
    "\n",
    "# x_train_scaled = x_train_scaled[:20]\n",
    "# y_train_scaled = y_train_scaled[:20]\n",
    "\n",
    "# x_train_scaled = sc.fit_transform(x_data[:100])\n",
    "# x_test_scaled = sc.transform(x_data[100:])\n",
    "# y_train_scaled = sc.fit_transform(y_data[:100])\n",
    "\n",
    "\n",
    "x_train_scaled = sc.fit_transform(x_train_data)\n",
    "x_test_scaled = sc.transform(x_test_data)\n",
    "y_train_scaled = sc.fit_transform(y_train_data)\n",
    "\n",
    "initial_n = x_train_scaled.shape[1]+2\n",
    "number_data = x_train_scaled.shape[0]\n",
    "\n",
    "print(\"initial_n:\",initial_n, \"number_data:\", number_data)\n",
    "\n",
    "x_train_scaled = x_train_scaled[:30]\n",
    "y_train_scaled = y_train_scaled[:30]\n",
    "\n",
    "\n",
    "initial_x = x_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "initial_y = y_train_scaled[:x_train_scaled.shape[1]+1]\n",
    "\n",
    "x_train_scaled = x_train_scaled[x_train_scaled.shape[1]+1:]\n",
    "y_train_scaled = y_train_scaled[x_train_scaled.shape[1]+1:]\n",
    "\n",
    "network = Network(4, initial_x, initial_y)\n",
    "initializing(network, initial_x, initial_y)\n",
    "\n",
    "\n",
    "# network.setData(x_train_scaled[:18], y_train_scaled[:18])\n",
    "# print(network.forward()[1])\n",
    "\n",
    "for i in range(initial_n, number_data): \n",
    "    \n",
    "    print(x_train_scaled.shape[0])\n",
    "    print(\"The data number: %d\"%i)\n",
    "    \n",
    "    sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "#     print(\"Selecting module finish!\")\n",
    "    \n",
    "    network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "    x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "    y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "    \n",
    "    yo, loss, tape = network.forward()\n",
    "    \n",
    "    print(tf.math.abs(yo-network.y))\n",
    "    \n",
    "    if tf.reduce_all(tf.math.abs(yo-network.y) <= network.threshold_for_error):\n",
    "        network.acceptable = True\n",
    "        network = reorganizing(network)\n",
    " \n",
    "    else:\n",
    "        \n",
    "        network.acceptable = False\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        network = matching(network)\n",
    "        \n",
    "        if network.acceptable:\n",
    "            network = reorganizing(network)\n",
    " \n",
    "        else:\n",
    "            network = network_pre\n",
    "            cramming(network)\n",
    "            network = reorganizing(network)\n",
    "\n",
    "#     print(network.b1)\n",
    "    print(network.acceptable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo, loss, tape = network.forward()\n",
    "plt.plot(sc.inverse_transform(yo)[:,0], label=\"LLAAT\")\n",
    "plt.plot(sc.inverse_transform(network.y)[:,0], label=\"Actual\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.forecast(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forecast(self, x_test_scaled):\n",
    "    \n",
    "#     x_test_scaled = tf.cast(x_test_scaled, tf.float32)\n",
    "#     forecast_value = tf.nn.relu((tf.matmul(x_test_scaled, self.W1)+self.b1))\n",
    "#     return forecast_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
