{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3ckGCsc59zR"
   },
   "source": [
    "## Import related API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DZ7-4Lqg3y5y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers, backend, optimizers\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, TimeDistributed, LeakyReLU, GRU, BatchNormalization\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 取消科學記號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foyEDjXa6FrE"
   },
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ckCcqkcQ4Zki"
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sbbk2VKh5LWS"
   },
   "outputs": [],
   "source": [
    "path = \"WeeklyFinalData.csv\"\n",
    "finalData = read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dkK-XcAq13_c"
   },
   "outputs": [],
   "source": [
    "train = finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = train[\"Date\"]\n",
    "train.drop(\"Date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# plt.plot(train[\"CCSP\"])\n",
    "# plt.axvline(x=381, color='r', linestyle='--')\n",
    "\n",
    "# plt.savefig('CCSP.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfVrRO09NWNE"
   },
   "source": [
    "## Visualization for raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7215,
     "status": "ok",
     "timestamp": 1616219762245,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "kBJtLYEyKEvb",
    "outputId": "37c0c5ec-2953-467d-cc0a-2891345cec55"
   },
   "outputs": [],
   "source": [
    "# def show_raw_visualization(data):\n",
    "\n",
    "#     fig, axes = plt.subplots(\n",
    "#         nrows=int(round(data.shape[1]/2,0)), ncols=2, figsize=(15, 20), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "#     )\n",
    "\n",
    "#     for i in range(data.shape[1]):\n",
    "#         t_data = data.iloc[:,i]\n",
    "#         ax = t_data.plot(\n",
    "#             ax=axes[i // 2, i % 2],\n",
    "#             color=\"black\",\n",
    "#             title=data.columns[i]\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('raw_data.png')\n",
    "\n",
    "\n",
    "# show_raw_visualization(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOMLTo856gQc"
   },
   "source": [
    "### Add lag time as a predicted factor \n",
    "1. Add lag time from 1 to 4 for CCSP (Yangtze River nonferrous metals, China)\n",
    "2. Split the data to Training set & Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dXrI2P985jos"
   },
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=1, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max scaling \n",
    "the data is scaled to a fixed range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q4tnCc9Ci5-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJl8fc4StNyV"
   },
   "source": [
    "### Setting the appearance of the learning graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PcEcx1JujxBF"
   },
   "outputs": [],
   "source": [
    "def show_raw_visualization(data, lag_time):\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=int(round(data.shape[1]/2,0)), ncols=2, figsize=(15, 5), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        t_data = data.iloc[:,i]\n",
    "        ax = t_data.plot(\n",
    "            ax=axes[i % 2],\n",
    "            color=\"black\",\n",
    "            title=\"Lag:{0}, {1} curve\".format(lag_time+1, data.columns[i])\n",
    "        )\n",
    "    \n",
    "#     fig.set_size_inches(10,15)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqNv5vJyPsBE"
   },
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXho5zzj6N9J"
   },
   "source": [
    "### 2-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "\n",
    "class DINKLE_Accuracy(Metric):\n",
    "\n",
    "    def __init__(self, name=\"DINKLE_Accuracy\", **kwargs):\n",
    "        super(Metric, self).__init__(name=name, **kwargs)\n",
    "#         self.total_count = self.add_weight(name = \"total_count\", initializer=init_ops.zeros_initializer)\n",
    "#         self.match_count = self.add_weight(name = \"match_count\", initializer=init_ops.zeros_initializer)\n",
    "        self.matches_rate = self.add_weight(name = \"matches_rate\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "#         y_true = tf.convert_to_tensor(sc.inverse_transform(y_true))\n",
    "#         y_pred = tf.convert_to_tensor(sc.inverse_transform(y_pred))\n",
    "            \n",
    "        match_count = tf.reduce_sum(tf.cast(tf.less_equal(tf.abs(y_true- y_pred), 0.02), dtype = tf.float32))\n",
    "        total_count = y_true.shape[0]\n",
    "        self.matches_rate = math_ops.div_no_nan(match_count, total_count)\n",
    "\n",
    "         \n",
    "    def result(self):\n",
    "        return  self.matches_rate\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.matches_rate = tf.zeros(shape=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1616227104464,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "BVmQxhxKwuJF"
   },
   "outputs": [],
   "source": [
    "def buildTwoLayerNN(training_data_shape, designated_units):\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=designated_units, activation =\"relu\", input_dim=training_data_shape, kernel_initializer = \"uniform\"))\n",
    "    regressor.add(Dense(units=1)) \n",
    "\n",
    "    adam = optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999, decay=1e-6)\n",
    "    regressor.compile(optimizer=adam, loss=\"mean_squared_error\", metrics=[tf.keras.metrics.RootMeanSquaredError(), DINKLE_Accuracy()])\n",
    "#     regressor.summary()\n",
    "\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 36064,
     "status": "ok",
     "timestamp": 1616227169191,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "9aCU6PXt7Ydb",
    "outputId": "0e52377e-238c-44e5-9df5-947d811b562c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Normalize---\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## Using different time lag\n",
    "\n",
    "\n",
    "## Time lag\n",
    "X1_train, Y1_train= buildTrain(train, pastWeek=4, futureWeek=1)\n",
    "\n",
    "## Split date to training & test data\n",
    "\n",
    "X1_training = pd.DataFrame(X1_train[0:int(X1_train.shape[0]*0.8)])\n",
    "X1_test = pd.DataFrame(X1_train[int(X1_train.shape[0]*0.8):])\n",
    "\n",
    "Y1_training = pd.DataFrame(Y1_train[0:int(Y1_train.shape[0]*0.8)])\n",
    "Y1_test = pd.DataFrame(Y1_train[int(Y1_train.shape[0]*0.8):])\n",
    "\n",
    "## Normalize\n",
    "print(\"---Normalize---\")\n",
    "X1_training_scaled = sc.fit_transform(X1_training)\n",
    "X1_test_scaled = sc.transform(X1_test)\n",
    "\n",
    "Y1_training_scaled = sc.fit_transform(Y1_training)\n",
    "Y1_test_scaled = sc.transform(Y1_test)\n",
    "\n",
    "#     -----------------<< Covert to tensor >>-----------------------\n",
    "X1_training_scaled = tf.convert_to_tensor(X1_training_scaled)\n",
    "X1_test_scaled = tf.convert_to_tensor(X1_test_scaled)\n",
    "\n",
    "Y1_training_scaled = tf.convert_to_tensor(Y1_training_scaled)\n",
    "Y1_test_scaled = tf.convert_to_tensor(Y1_test_scaled)\n",
    "\n",
    "\n",
    "## Training model\n",
    "input_sahpe = X1_training_scaled.shape[1]\n",
    "regressor = buildTwoLayerNN(input_sahpe, 30)\n",
    "history = regressor.fit(X1_training_scaled, Y1_training_scaled, epochs=3, batch_size=10, verbose=0)\n",
    "\n",
    "#     score = regressor.evaluate(X1_test_scaled, Y1_test_scaled, batch_size=X1_test_scaled.shape[0],verbose=0)\n",
    "\n",
    "print(len(history.history[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.039\n",
      "0.059\n",
      "0.078\n",
      "0.098\n",
      "0.117\n"
     ]
    }
   ],
   "source": [
    "for i in range(500, 3001, 500):\n",
    "    print(round((i/25601),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.472884251997269>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(X1_test_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5e287fe422e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "print(precision(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gBc6cwE_X1e"
   },
   "source": [
    "### SVR using linear/ polynominal/ RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1616226931437,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "32akjdf5DIUe"
   },
   "outputs": [],
   "source": [
    "def predict_prices(X_training, Y_training, X_testing, Y_testing):\n",
    "    \n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    svr_poly = SVR(kernel = 'poly', C=1e3 , degree = 2 )\n",
    "    svr_rbf = SVR(kernel = 'rbf', C=1e3 , gamma = 0.1)\n",
    "    svr_lin.fit(X_training, Y_training)    \n",
    "    svr_poly.fit(X_training, Y_training)\n",
    "    svr_rbf.fit(X_training, Y_training)\n",
    "    \n",
    "\n",
    "    svrs = [svr_lin, svr_poly, svr_rbf]\n",
    "    kernel_label = ['Linear', 'Polynomial', 'RBF']\n",
    "    model_color = ['g', 'b', 'r']\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 15), sharey=True)\n",
    "    \n",
    "    for ix, svr in enumerate(svrs):\n",
    "\n",
    "#         train_obs = sc.inverse_transform(pd.DataFrame(Y_training))\n",
    "#         train_pre = sc.inverse_transform(pd.DataFrame(svr.predict(X_training)))\n",
    "\n",
    "#         test_obs = sc.inverse_transform(pd.DataFrame(Y_testing))\n",
    "#         test_pre = sc.inverse_transform(pd.DataFrame(svr.predict(X_testing)))\n",
    "\n",
    "        train_obs = Y_training\n",
    "        train_pre = svr.predict(X_training)\n",
    "\n",
    "        test_obs = Y_testing\n",
    "        test_pre = svr.predict(X_testing)\n",
    "\n",
    "        axes[0, ix].scatter(range(Y_training.shape[0]), train_obs, color='black', label = 'data')\n",
    "        axes[0, ix].plot(train_pre, color= model_color[ix], label =kernel_label[ix])\n",
    "        axes[0, ix].legend()\n",
    "        axes[0, ix].set_title(\"Training Step: \"+kernel_label[ix]+\" kenel\")\n",
    "        axes[0, ix].set_xlabel(\"Sample index(weekly)\")\n",
    "        axes[0, ix].set_ylabel(\"Copper price ($/ton)\")\n",
    "        \n",
    "        axes[1, ix].scatter(range(Y_testing.shape[0]), test_obs, color='black', label = 'data')\n",
    "        axes[1, ix].plot(test_pre, color= model_color[ix], label =kernel_label[ix])\n",
    "        axes[1, ix].legend()\n",
    "        axes[1, ix].set_title(\"Testing Step: \"+kernel_label[ix]+\" kenel\")\n",
    "        axes[1, ix].set_xlabel(\"Sample index(weekly)\")\n",
    "        axes[1, ix].set_ylabel(\"Copper price ($/ton)\")\n",
    "        \n",
    "        training_RMSE = np.sqrt(mean_squared_error(train_obs, train_pre))\n",
    "        testing_RMSE = np.sqrt(mean_squared_error(test_obs, test_pre))\n",
    "\n",
    "        print(\"The RMSE of SVR using %s kenel\\nTraining step:%.3f\\tTest step:%.3f\" %(kernel_label[ix], training_RMSE, testing_RMSE))\n",
    "\n",
    "    fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6025,
     "status": "ok",
     "timestamp": 1616226940570,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "d_2EiJnnBWfp",
    "outputId": "2359988d-3c02-49c4-8e40-bf0188b8c3b9"
   },
   "outputs": [],
   "source": [
    "## Using different time lag\n",
    "for i in range(4):\n",
    "\n",
    "    print(\"Lag time = {}\".format(i+1))\n",
    "    ## Time lag\n",
    "    X1_train, Y1_train= buildTrain(train, pastWeek=i+1, futureWeek=1)\n",
    "\n",
    "    ## Split date to training & test data\n",
    "    X1_training = pd.DataFrame(X1_train[0:int(X1_train.shape[0]*0.8)])\n",
    "    X1_test = pd.DataFrame(X1_train[int(X1_train.shape[0]*0.8):])\n",
    "\n",
    "    Y1_training = pd.DataFrame(Y1_train[0:int(Y1_train.shape[0]*0.8)])\n",
    "    Y1_test = pd.DataFrame(Y1_train[int(Y1_train.shape[0]*0.8):])\n",
    "\n",
    "    ## Normalize\n",
    "    print(\"---Normalize---\")\n",
    "    X1_training_scaled = sc.fit_transform(X1_training)\n",
    "    X1_test_scaled = sc.transform(X1_test)\n",
    "\n",
    "    Y1_training_scaled = sc.fit_transform(Y1_training)\n",
    "    Y1_test_scaled = sc.transform(Y1_test)\n",
    "\n",
    "    ## Training model\n",
    "    predict_prices(X1_training_scaled, Y1_training_scaled, X1_test_scaled, Y1_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPCE9feoFe+aUJB0/gpNn3r",
   "collapsed_sections": [],
   "name": "2-layer Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
