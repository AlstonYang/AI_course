{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3ckGCsc59zR"
   },
   "source": [
    "### Import related API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3044,
     "status": "ok",
     "timestamp": 1616838642242,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "DZ7-4Lqg3y5y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers, backend\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, TimeDistributed, LeakyReLU, GRU, BatchNormalization\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control the upper limit of GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20157,
     "status": "ok",
     "timestamp": 1616838659374,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "HovSE_YS9AEO",
    "outputId": "d327c0b4-23c7-4c81-8577-38a0118688d2"
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20721,
     "status": "ok",
     "timestamp": 1616838659941,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "GxcSLwVY9FKy"
   },
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=1, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 20719,
     "status": "ok",
     "timestamp": 1616838659942,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "dkK-XcAq13_c"
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data)\n",
    "    \n",
    "    ## Data split\n",
    "    x_train = x_data[0:int(x_data.shape[0]*0.8)]\n",
    "    x_test = x_data[int(x_data.shape[0]*0.8):]\n",
    "    \n",
    "    y_train = y_data[0:int(y_data.shape[0]*0.8)]\n",
    "    y_test = y_data[int(y_data.shape[0]*0.8):]\n",
    "    \n",
    "    ## Normalize\n",
    "    x_train_scaled = sc.fit_transform(x_train)\n",
    "    x_test_scaled = sc.transform(x_test)\n",
    "    \n",
    "    y_train_scaled = sc.fit_transform(y_train)\n",
    "    y_test_scaled = sc.transform(y_test)\n",
    "    \n",
    "    ## Other information\n",
    "    nb_output = 1\n",
    "    input_shape = x_train_scaled.shape[1]\n",
    "    \n",
    "    return (nb_output, input_shape, x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_output, input_shape, x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJl8fc4StNyV"
   },
   "source": [
    "### Setting the format of the learning graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 20711,
     "status": "ok",
     "timestamp": 1616838659944,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "PcEcx1JujxBF"
   },
   "outputs": [],
   "source": [
    "def show_raw_visualization(data):\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=int(round(data.shape[1]/2,0)), ncols=2, figsize=(15, 5), dpi=80, facecolor=\"w\", edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        t_data = data.iloc[:,i]\n",
    "        ax = t_data.plot(\n",
    "            ax=axes[i % 2],\n",
    "            color=\"black\",\n",
    "            # title=\"Lag:{0}, {1} curve\".format(lag_time+1, data.columns[i])\n",
    "        )\n",
    "    \n",
    "#     fig.set_size_inches(10,15)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqNv5vJyPsBE"
   },
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXho5zzj6N9J"
   },
   "source": [
    "### 2-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 20695,
     "status": "ok",
     "timestamp": 1616838659945,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "BVmQxhxKwuJF"
   },
   "outputs": [],
   "source": [
    "def buildTwoLayerNN(training_data_shape, setting):\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    regressor = Sequential()\n",
    "    L2 = tf.keras.regularizers.L2(setting[4])\n",
    "    regressor.add(Dense(units=setting[1], activation =setting[0], input_dim=training_data_shape, kernel_initializer = setting[2], kernel_regularizer= L2))\n",
    "    regressor.add(Dense(units=1)) \n",
    "\n",
    "    # adam = optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999, decay=1e-6)\n",
    "\n",
    "    regressor.compile(optimizer=setting[3], loss=\"mean_squared_error\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    # regressor.summary()\n",
    "\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_eva(raw_data, predict_data):\n",
    "    \n",
    "    total_times = raw_data.shape[0]\n",
    "    accuracy_indicator = []\n",
    "  ##Test\n",
    "#     print(type(raw_data))\n",
    "#     print(type(predict_data))\n",
    "\n",
    "    for threshold in range(1000,3001,1000):\n",
    "        correct_times = 0\n",
    "        \n",
    "        for i in range(raw_data.shape[0]): \n",
    "\n",
    "            if tf.abs(raw_data[i]-predict_data[i]) <= threshold:\n",
    "                correct_times +=1\n",
    "\n",
    "        accuracy_indicator.append(correct_times/total_times)\n",
    "    \n",
    "    return (accuracy_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 20689,
     "status": "ok",
     "timestamp": 1616838659945,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "ItBqvK4L9-UN"
   },
   "outputs": [],
   "source": [
    "def training_model(setting, setting_name):\n",
    "\n",
    "    ## data\n",
    "    nb_output, input_shape, x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = get_data()\n",
    "\n",
    "    ## Training model\n",
    "\n",
    "    #training_data_shape, activation_function, hidden_node, initializer, optimizer\n",
    "    regressor = buildTwoLayerNN(input_shape, setting[1:])\n",
    "    history = regressor.fit(x=x_train_scaled, y=y_train_scaled, epochs= 16, verbose=0)\n",
    "\n",
    "    ## Draw the learning graph\n",
    "    RMSE = [i for i in history.history[\"root_mean_squared_error\"]]\n",
    "    score_data = pd.DataFrame({\"Loss\":history.history[\"loss\"], \"RMSE\":RMSE})\n",
    "\n",
    "    ## Evaluate the model using testing data\n",
    "    # scores = regressor.evaluate(data[2], data[3])  \n",
    "\n",
    "    ##Test\n",
    "    predict = regressor.predict(x_test_scaled)\n",
    "    ##Test\n",
    "    \n",
    "#     if (np.isnan(predict).sum()>0):\n",
    "#         print(setting_name)\n",
    "#         score = float(\"inf\")\n",
    "#         accuracy = 0\n",
    "    \n",
    "#     else:\n",
    "\n",
    "    Y_testing_data =  y_test_scaled\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_eva(Y_testing_data, predict)\n",
    "    \n",
    "    performance = {\n",
    "        \"Epochs\":setting_name[0],\n",
    "        \"Activation function\":setting_name[1],\n",
    "        \"Hidden nodes\":setting_name[2],\n",
    "        \"Initializer\":setting_name[3],\n",
    "        \"Optimizer\":setting_name[4],\n",
    "        \"Regularizer\":setting_name[5],\n",
    "        \"In-sample RMSE\": score_data[\"RMSE\"],\n",
    "        \"Out-of-sample Accuracy(1000)\": accuracy[0],\n",
    "        \"Out-of-sample Accuracy(2000)\": accuracy[1],\n",
    "        \"Out-of-sample Accuracy(3000)\": accuracy[2]\n",
    "    }\n",
    "    \n",
    "\n",
    "    ##Test\n",
    "    predicts = pd.DataFrame(predict)\n",
    "    \n",
    "    return performance, predicts.stack().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control model Hyperparameter\n",
    "such as:\n",
    "* input factor dimension\n",
    "* epoch\n",
    "* activation_function\n",
    "* hidden_node\n",
    "* initializer\n",
    "* optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 21140,
     "status": "error",
     "timestamp": 1616838660407,
     "user": {
      "displayName": "楊仁瀚",
      "photoUrl": "",
      "userId": "10638930497464391672"
     },
     "user_tz": -480
    },
    "id": "vxaHHmlcDxkt",
    "outputId": "f3bddc5f-f230-491b-bd9f-10930a74f763"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    ## data, epoch, activation_function, hidden_node, initializer, optimizer\n",
    "    ## epoches, activation_functions, hidden_nodes選項\n",
    "    \n",
    "    ### 0, 1, 2\n",
    "    epoches = range(10, 301)\n",
    "    activation_functions = [\"sigmoid\", \"tanh\", \"relu\"]\n",
    "    hidden_nodes = range(3, 50)\n",
    "\n",
    "    ## initializer 選項\n",
    "    small_random = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "    Xavier = tf.keras.initializers.GlorotNormal()\n",
    "    \n",
    "    ### 3\n",
    "    initializers = [small_random, Xavier]\n",
    "    initializers_name = [\"small_random\", \"Xavier\"]\n",
    "\n",
    "    # optimizer & learning rate decay\n",
    "    learning_rate_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate = 0.01, \n",
    "        decay_steps = 10,\n",
    "        alpha = 0.01\n",
    "    )\n",
    "\n",
    "    SGD_cosine = tf.keras.optimizers.SGD(\n",
    "      learning_rate=learning_rate_fn,\n",
    "      name = \"SGD_with_cosine\"\n",
    "    )\n",
    "\n",
    "    Adam_cosine = tf.keras.optimizers.Adam(\n",
    "      learning_rate=learning_rate_fn,\n",
    "      name = \"Adam_with_cosine\"\n",
    "    )\n",
    "\n",
    "    Momentum = tf.keras.optimizers.SGD(\n",
    "      learning_rate=0.01,\n",
    "      momentum=0.9,\n",
    "      name = \"Momentum\"\n",
    "    )\n",
    "\n",
    "    Mom_cosine = tf.keras.optimizers.SGD(\n",
    "      learning_rate=learning_rate_fn,\n",
    "      momentum=0.9,\n",
    "      name = \"Momentum_with_cosine\"\n",
    "    )\n",
    "    \n",
    "    ## optimizers 選項\n",
    "    ### 4\n",
    "    optimizers = [\"SGD\", SGD_cosine, \"Adam\", Adam_cosine, Momentum, Mom_cosine]\n",
    "    optimizers_name = [\"SGD\", \"SGD_with_cosine\", \"Adam\", \"Adam_with_cosine\", \"Momentum\", \"Momentum_with_cosine\"]\n",
    "\n",
    "    ## regularizers 選項\n",
    "    ### 5\n",
    "    regularizer= np.arange(0,0.0011, 0.0001)\n",
    "    \n",
    "    ##Test\n",
    "#     optimizers = [\"SGD\",\"Adam\"]\n",
    "#     optimizers_name = [\"SGD\",\"Adam\"]\n",
    "\n",
    "    ##所有hyperparameter的組合\n",
    "    sets = list(product(epoches, activation_functions, hidden_nodes, initializers, optimizers, regularizer))\n",
    "    sets_name = list(product(epoches, activation_functions, hidden_nodes, initializers_name, optimizers_name, regularizer))\n",
    "\n",
    "    ### Performance indicator\n",
    "    RMSE_scores = pd.DataFrame(columns = [\"Epochs\", \"Activation function\", \"Hidden nodes\", \"Initializer\", \"Optimizer\", \"Regularizer\",\"In-sample RMSE\", \"Out-of-sample Accuracy(1000)\", \"Out-of-sample Accuracy(2000)\", \"Out-of-sample Accuracy(3000)\"])\n",
    "    predicts = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(sets)):\n",
    "        \n",
    "        performance, predict = training_model(sets[i], sets_name[i])\n",
    "        \n",
    "        RMSE_scores = RMSE_scores.append(performance, ignore_index=True)\n",
    "        predicts = predicts.append(predict, ignore_index=True)\n",
    "\n",
    "    return RMSE_scores, predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f413d234840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f413d036378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    RMSE_scores, predicts = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best top five models based on in-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_scores.sort_values(\"In-sample RMSE\", inplace=True)\n",
    "RMSE_scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble the top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_model = predicts.iloc[list(RMSE_scores.head(5).index),:]\n",
    "ensemble_predict = top_five_model.apply(lambda x: x.mean())\n",
    "ensemble_RMSE = np.sqrt(mean_squared_error(ensemble_predict, data[3]))\n",
    "emsemble_accuracy = accuracy_eva(data[3], ensemble_predict, 3000)\n",
    "print(\"RMSE of ensembling the top 5 models: %.5f\" %ensemble_RMSE)\n",
    "print(\"Accuracy of ensembling the top 5 models: %.5f\" %emsemble_accuracy)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(range(data[3].shape[0]), data[3], color='black', label = 'Raw data')\n",
    "plt.plot(ensemble_predict, label = 'Predicted value')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sample index (weekly)\")\n",
    "plt.ylabel(\"Cooper price value\")\n",
    "plt.savefig('Result_ensemble_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the results of model configuration in in-sample data as Settings_RMSE_scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_scores.reset_index(inplace=True, drop=True)\n",
    "RMSE_scores.to_csv(\"Settings_score_DINKLE.csv\", index=False)\n",
    "RMSE_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best configuration in out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_scores.sort_values(\"Out-of-sample RMSE\", inplace=True)\n",
    "RMSE_scores.reset_index(inplace=True, drop=True)\n",
    "RMSE_scores[RMSE_scores[\"Out-of-sample RMSE\"]==min(RMSE_scores[\"Out-of-sample RMSE\"])]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
